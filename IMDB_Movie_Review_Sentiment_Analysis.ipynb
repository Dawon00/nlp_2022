{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPphfuQdMQvb78CMO8xwRU5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dawon00/nlp_2022/blob/main/IMDB_Movie_Review_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "JPN3hSYZAix3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import imdb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = imdb.load_data()\n",
        "\n",
        "print('훈련용 리뷰 개수 : {}'.format(len(X_train)))\n",
        "print('테스트용 리뷰 개수 : {}'.format(len(X_test)))\n",
        "num_classes = len(set(y_train))\n",
        "print('카테고리 : {}'.format(num_classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGrqP5a3BH_a",
        "outputId": "0465df7b-4817-4c16-82b2-d76efe76f82f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련용 리뷰 개수 : 25000\n",
            "테스트용 리뷰 개수 : 25000\n",
            "카테고리 : 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('첫번째 훈련용 리뷰 :',X_train[0])\n",
        "print('첫번째 훈련용 리뷰의 레이블 :',y_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaQZgMJQBJGb",
        "outputId": "db76ec76-a36a-4232-8494-6dc7f3252351"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "첫번째 훈련용 리뷰 : [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
            "첫번째 훈련용 리뷰의 레이블 : 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_length = [len(review) for review in X_train]\n",
        "print('리뷰의 최대 길이 : {}'.format(np.max(reviews_length)))\n",
        "print('리뷰의 평균 길이 : {}'.format(np.mean(reviews_length)))\n",
        "\n",
        "#plt.subplot(1,2,1)\n",
        "#plt.boxplot(reviews_length)\n",
        "#plt.subplot(1,2,2)\n",
        "#plt.hist(len_result, bins=50)\n",
        "#plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpH0RimZBMAf",
        "outputId": "e51cd112-7d96-4182-f887-8cc7381ce2a1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "리뷰의 최대 길이 : 2494\n",
            "리뷰의 평균 길이 : 238.71364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_elements, counts_elements = np.unique(y_train, return_counts=True)\n",
        "print(\"각 레이블에 대한 빈도수:\")\n",
        "print(np.asarray((unique_elements, counts_elements)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ui12noYuBRpb",
        "outputId": "45e92c40-8dd7-4701-8a00-a9e7d8b4c077"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "각 레이블에 대한 빈도수:\n",
            "[[    0     1]\n",
            " [12500 12500]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_index = imdb.get_word_index()\n",
        "index_to_word = {}\n",
        "for key, value in word_to_index.items():\n",
        "    index_to_word[value+3] = key"
      ],
      "metadata": {
        "id": "4fGELPfRBVxW"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('빈도수 상위 1등 단어 : {}'.format(index_to_word[4]))\n",
        "print('빈도수 상위 3938등 단어 : {}'.format(index_to_word[3941]))\n",
        "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
        "  index_to_word[index] = token\n",
        "\n",
        "print(' '.join([index_to_word[index] for index in X_train[0]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZLDWQfpBYtg",
        "outputId": "b3dd1a65-6058-4685-f33a-079b7288eba8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "빈도수 상위 1등 단어 : the\n",
            "빈도수 상위 3938등 단어 : suited\n",
            "<sos> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert redford's is an amazing actor and now the same being director norman's father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for retail and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also congratulations to the two little boy's that played the part's of norman and paul they were just brilliant children are often left out of the praising list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GRU, Embedding\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "vocab_size = 8000\n",
        "max_len = 300\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
        "\n",
        "X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = pad_sequences(X_test, maxlen=max_len)"
      ],
      "metadata": {
        "id": "RHuF1BraBfFY"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 100\n",
        "hidden_units = 100\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim))\n",
        "model.add(GRU(hidden_units))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "mc = ModelCheckpoint('GRU_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = model.fit(X_train, y_train, epochs=15, callbacks=[es, mc], batch_size=32, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YE-DiH3bBilR",
        "outputId": "a4350d55-b590-43f8-ffc0-bf1af36a5d3b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "623/625 [============================>.] - ETA: 0s - loss: 0.4501 - acc: 0.7906\n",
            "Epoch 1: val_acc improved from -inf to 0.83340, saving model to GRU_model.h5\n",
            "625/625 [==============================] - 12s 16ms/step - loss: 0.4500 - acc: 0.7908 - val_loss: 0.3827 - val_acc: 0.8334\n",
            "Epoch 2/15\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.2843 - acc: 0.8863\n",
            "Epoch 2: val_acc improved from 0.83340 to 0.89000, saving model to GRU_model.h5\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.2843 - acc: 0.8863 - val_loss: 0.2743 - val_acc: 0.8900\n",
            "Epoch 3/15\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.2099 - acc: 0.9195\n",
            "Epoch 3: val_acc did not improve from 0.89000\n",
            "625/625 [==============================] - 10s 15ms/step - loss: 0.2099 - acc: 0.9196 - val_loss: 0.3104 - val_acc: 0.8762\n",
            "Epoch 4/15\n",
            "623/625 [============================>.] - ETA: 0s - loss: 0.1630 - acc: 0.9388\n",
            "Epoch 4: val_acc improved from 0.89000 to 0.89500, saving model to GRU_model.h5\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.1630 - acc: 0.9388 - val_loss: 0.2533 - val_acc: 0.8950\n",
            "Epoch 5/15\n",
            "622/625 [============================>.] - ETA: 0s - loss: 0.1336 - acc: 0.9524\n",
            "Epoch 5: val_acc did not improve from 0.89500\n",
            "625/625 [==============================] - 11s 17ms/step - loss: 0.1335 - acc: 0.9524 - val_loss: 0.2745 - val_acc: 0.8948\n",
            "Epoch 6/15\n",
            "623/625 [============================>.] - ETA: 0s - loss: 0.1109 - acc: 0.9607\n",
            "Epoch 6: val_acc did not improve from 0.89500\n",
            "625/625 [==============================] - 10s 15ms/step - loss: 0.1110 - acc: 0.9607 - val_loss: 0.2787 - val_acc: 0.8864\n",
            "Epoch 7/15\n",
            "625/625 [==============================] - ETA: 0s - loss: 0.0890 - acc: 0.9683\n",
            "Epoch 7: val_acc did not improve from 0.89500\n",
            "625/625 [==============================] - 10s 16ms/step - loss: 0.0890 - acc: 0.9683 - val_loss: 0.3188 - val_acc: 0.8904\n",
            "Epoch 8/15\n",
            "624/625 [============================>.] - ETA: 0s - loss: 0.0727 - acc: 0.9766\n",
            "Epoch 8: val_acc did not improve from 0.89500\n",
            "625/625 [==============================] - 10s 15ms/step - loss: 0.0728 - acc: 0.9765 - val_loss: 0.3554 - val_acc: 0.8880\n",
            "Epoch 8: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ef1R_UzfL_7A",
        "outputId": "7866cdbe-56ee-4e79-a2c8-b403773cdae0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, None, 100)         800000    \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 100)               60600     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 860,701\n",
            "Trainable params: 860,701\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_model = load_model('GRU_model.h5')\n",
        "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQJ9LAjSBlOa",
        "outputId": "d1145326-1530-4cbf-db74-5d30711ed636"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 6s 7ms/step - loss: 0.2566 - acc: 0.8947\n",
            "\n",
            " 테스트 정확도: 0.8947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiment_predict(new_sentence):\n",
        "  # 알파벳과 숫자를 제외하고 모두 제거 및 알파벳 소문자화\n",
        "  new_sentence = re.sub('[^0-9a-zA-Z ]', '', new_sentence).lower()\n",
        "  encoded = []\n",
        "\n",
        "  # 띄어쓰기 단위 토큰화 후 정수 인코딩\n",
        "  for word in new_sentence.split():\n",
        "    try :\n",
        "      # 단어 집합의 크기를 10,000으로 제한.\n",
        "      if word_to_index[word] <= 10000:\n",
        "        encoded.append(word_to_index[word]+3)\n",
        "      else:\n",
        "      # 10,000 이상의 숫자는 <unk> 토큰으로 변환.\n",
        "        encoded.append(2)\n",
        "    # 단어 집합에 없는 단어는 <unk> 토큰으로 변환.\n",
        "    except KeyError:\n",
        "      encoded.append(2)\n",
        "\n",
        "  pad_sequence = pad_sequences([encoded], maxlen=max_len)\n",
        "  score = float(loaded_model.predict(pad_sequence)) # 예측\n",
        "\n",
        "  if(score > 0.5):\n",
        "    print(\"{:.2f}% 확률로 긍정 리뷰입니다.\".format(score * 100))\n",
        "  else:\n",
        "    print(\"{:.2f}% 확률로 부정 리뷰입니다.\".format((1 - score) * 100))"
      ],
      "metadata": {
        "id": "LOTyVP38BoHs"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_input = \"This movie was just way too overrated. The fighting was not professional and in slow motion. I was expecting more from a 200 million budget movie. The little sister of T.Challa was just trying too hard to be funny. The story was really dumb as well. Don't watch this movie if you are going because others say its great unless you are a Black Panther fan or Marvels fan.\"\n",
        "\n",
        "sentiment_predict(test_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-pKMlS3BrZ4",
        "outputId": "e8b54d4b-f334-4301-bc27-48d38acb5bcc"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 307ms/step\n",
            "98.20% 확률로 부정 리뷰입니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_input = \" I was lucky enough to be included in the group to see the advanced screening in Melbourne on the 15th of April, 2012. And, firstly, I need to say a big thank-you to Disney and Marvel Studios. \\\n",
        "Now, the film... how can I even begin to explain how I feel about this film? It is, as the title of this review says a 'comic book triumph'. I went into the film with very, very high expectations and I was not disappointed. \\\n",
        "Seeing Joss Whedon's direction and envisioning of the film come to life on the big screen is perfect. The script is amazingly detailed and laced with sharp wit a humor. The special effects are literally mind-blowing and the action scenes are both hard-hitting and beautifully choreographed.\"\n",
        "\n",
        "sentiment_predict(test_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puf-HJynBt-y",
        "outputId": "691aa26d-b57d-4b76-c795-a1530025faf0"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n",
            "99.00% 확률로 긍정 리뷰입니다.\n"
          ]
        }
      ]
    }
  ]
}